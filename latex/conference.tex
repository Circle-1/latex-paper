\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{tikz}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
\makeatletter
\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}
\makeatother

\begin{document}

\title{Analysis of Stock Market data and providing predictions using CNN-LSTM Neural Network model\\
}

\author{\IEEEauthorblockN{Aadhitya A}
\IEEEauthorblockA{\textit{Department of Information Technology} \\
\textit{Madras Institute of Technology}\\
Chennai, India \\
Email: aadhitya864@gmail.com}
\and
\IEEEauthorblockN{Rajapriya R}
\IEEEauthorblockA{\textit{Department of Information Technology} \\
\textit{Madras Institute of Technology}\\
Chennai, India \\
}
\and
\IEEEauthorblockN{Vineetha R S}
\IEEEauthorblockA{\textit{Department of Information Technology} \\
\textit{Madras Institute of Technology}\\
Chennai, India \\
}
\linebreakand
\IEEEauthorblockN{Anurag M Bagde}
\IEEEauthorblockA{\textit{Department of Information Technology} \\
\textit{Madras Institute of Technology}\\
Chennai, India \\
}
}

\maketitle

\begin{abstract}
Stock market is often important as it represents the ownership claims on businesses. Without sufficient stocks, a company cannot perform well in finance. Predicting a stock market performance of a company is nearly hard because every time the prices of a company’s stock keeps changing and not constant. Therefore, it’s random to predict and pick the right company to buy or sell stocks. But if the previous performance of a company in stock market is known, then we can track the data and provide predictions (which is near accurate) to the stockholders to wisely take decisions on handling the stocks to a company. To handle this, many machine learning models have been invented but they didn't succeed due to many reasons like absence of advanced libraries, inaccuracy of model when made to train with real time data and much more. So, to track the patterns and the features of data, a CNN-LSTM Neural Network can be made. Recently, CNN is now used in Natural Language Processing (NLP) based applications, so by identifying the features from stock data and converting them into tensors, we can obtain the features and then send it to LSTM neural network to find the patterns and thereby predicting the stock market for given period of time. The accuracy of the CNN-LSTM NN model is found to be high even when allowed to train on real-time stock market data. This paper describes about the features of the CNN-LSTM model, experiments we made with the model like training with stock market datasets, performance comparison with other models and the end product we obtained at final stage.
\end{abstract}

\begin{IEEEkeywords}
CNN-LSTM, Deep Learning, Prediction, Pattern Recognition
\end{IEEEkeywords}

\section{Introduction}
Stock Market (also called as share market) is a place where people or businessmen often look on their "shares" or ownership claims related to the company. Stock market is considered an important place in economy as a country's wealth is decided on it. The hardest task in stock market is predicting it because the data is not constant, always. In early days, many people tried to predict stocks using conventional methods but most of the time, failed. So the probability of predicting stocks correctly is very minimal. Today, Machine Learning (ML) techniques have been implemented to predict the company shares and thereby providing suggestions to stock holders to improvise the company's performance. But however, they are not accurate. This paper focuses on some of the works done in predicting stock market and a new method to follow CNN-LSTM Neural Network model approach to predict data for given time-series.

\section{Related Work}

Before the time of writing this paper, many have proposed and implemented various algorithms in order to predict stock market data. We did a literature survey to find some of the algorithms proposed and found some of the advantages, disadvantages present in those algorithms. Subhadra and Kalyana in \cite{b1} conducted analysis in various machine learning methods to predict stock market data and found that Random Forest performs good compared with Linear Regression and other algorithms, however the error percentage rises in the model when the input data is not smoothed in pre-processing stage. Pang, Zhou et al in \cite{b2} made comparisons with RNN and LSTM model and conducted experimental analysis, in which LSTM with Auto-Encoder module enabled (AELSTM) predicted most of the data but the implementation is done using old libraries and with real-time stock market data, thus the accuracy of the model was low. This was improved but revealed an important point when a model is made to train with real-time data. Uma and Kotrappa in \cite{b3} proposed a new method where LSTM with Log Bilinear layer before it predicted most of the stock market data and turned out with high accuracy but it was proposed and not tested with real time data, also it was meant to predict data only during the time of COVID-19 and not beyond that. Kimoto, Yoda, Takeoka in \cite{b4} discussed a buying and selling timing prediction system based on modular neural network which converts the technical indexes and economic indexes into a space pattern to input to the neural networks. During the analysis phase, neural network model produced a higher correlation coefficient in comparison to multiple regression. The experiment did by Guresen, Kayakutlu and Daim in \cite{b5} evaluates the efficiency of dynamic artificial neural network (DAN2), multi-layer perceptron (MLP), and hybrid neural networks. The paper concludes by stating that the classic ANN model - MLP gives the most reliable results in forecasting time series while Hybrid methods failed to improve the forecast results. Nelson, Pereira and Oliveria in \cite{b6} proposed an LSTM network to predict future trends of stock prices in time steps of 15 minutes based on the price history, alongside technical analysis indicators. On average  55.9\% accuracy was achieved in predicting whether the price of a particular stock may increase or not shortly in the future. Selvin, Menon, Soman et al in \cite{b7} experimented on three different deep learning models, namely CNN, RNN, and LSTM with a sliding window approach. Out of the three, CNN gave more accurate results than the other two models which is due to the reason that CNN uses only the information on the current window for predicting stock price. This allows CNN  to understand the dynamic changes and patterns occurring in the current window. Conversely, RNN and LSTM use information from previous lags for predicting future instances. Hiransha, Gopalakrishnan and Soman in \cite{b8} conducted experiments to compare different Deep Learning models viz. ANN, MLP, LSTM, and RNN. ANN captured the pattern at the initial stage so did RNN but on reaching a certain time period both failed to identify the pattern. Same was the case with LSTM but CNN seemed to perform better compared to the other three networks even though several time periods showed less accuracy for the predicted values. Bansal, Hasija et al in \cite{b9} proposed an Intelligent decentralized Stock market model using the convergence of machine learning alongside DAG-based cryptocurrency. The ML model which is based on LSTM achieved an accuracy of 99.71\%  in prediction. The feature vector of stock for the company contained 4 parameter values i.e. ‘open’, ‘close’, ‘low’, and ‘high’ with batch size as 50 for 100 epochs.  

% use \cite for references! IMPORTANT!

\section{Proposed Work}
After we conducted the literature survey, we realised some of the key points to be taken while designing a ML model
\begin{itemize}
\item The model must be designed in such a way that it should parse real-time data and not just sample data
\item The data has to be preprocessed correctly in order to avoid errors during training and testing phase
\item The accuracy of the model not only depends upon it's parameters but the dataset as well
\item The only point most of the papers didn't mention is the deployment, as it's one of the most important fact while creating a model
\end{itemize}
Considering the above key points, we focused on making the ML model. We decided to go on with CNN-LSTM Neural Network (Convolutional Neural Network and Long Term Short Memory Neural Network) approach because CNN helps in tracking the features of dataset and LSTM helps in tracking the patterns, allowing to train on them. This approach isn't the first time as some already tried to implement it but we tweaked the parameters and layers to experiment and test it on real-time data. Since this is a regression type of problem where we had to train with time-series data, we used Mean Square Error as the standard metric rather than accuracy (because accuracy will return 0.0000+e00 even if loss value is present)

Considering the fact that user experience must be stable and good, we designed a simple architecture diagram to understand the basic working of the full-stack web application. This is shown in Fig. \ref{simple-arch}.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.07]{SI - Arch.png}}
\caption{Architecture diagram for web app}
\label{simple-arch}
\end{figure}

For the neural network, we first analysed with other works and then decided the architecture in order to maintain novelty. The architecture diagram for the neural network is shown in Fig. \ref{model-sam}.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.2]{Model-sam.png}}
\caption{Architecture for neural network (sample)}
\label{model-sam}
\end{figure}

\textbf{NOTE: For this project, we mainly used Python and Jupyter Notebooks to perform the experiment. To see the experiment we did, refer \url{https://github.com/Circle-1/Stock-X}}

\section{Experimental Analysis}
For the experiment, we used Python for data preprocessing and creating a Neural Network model. For the application part, we used Flask framework using Python for backend and NextJS framework using JavaScript for frontend. For deployment, it's considered as minimal because, we saved the model in HDF5 format using Keras, but in addition to that, we made a Docker Image and Helm charts for people to work on. In this section, the major parts of the project and the experiments performed are described.

\subsection{Data Preprocessing and Analysis}\label{A}
In the process of creating a ML model, the first and foremost step is the data processing step; without that the model's accuracy won't be stable. So for this phase, we first cleansed the data by removing NULL values from the dataset and taking the mean of data and replacing it if necessary using Pandas library. Then we took the four columns of any stock market dataset, namely "Open", "Close", "High", "Low". These are the columns which mainly involve in training the dataset especially "Close" column (shown in Fig. \ref{dataset-1}). The graphs are plotted using the matplotlib library in Python. After making a primary analysis, we then went towards the preprocessing step.

Before we went on working towards preprocessing, we realised that CNN always considers 2-Dimensional arrays to train and select required features. But here, the data we have is of 1-Dimensional arrays. This is why CNN is always seen in Computer Vision (CV) based applications and not in NLP based applications. 

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.7]{Annotation-1.png}}
\caption{Example of stock market dataset}
\label{dataset-1}
\end{figure}

So, in order for CNN model to parse the dataset, we made a function where the 1-D arrays are made to convert to [100,1] tensor (precisely, a vector). Tensors are a type of data structures that describe a mulilinear relationship between set of objects in a vector space. So, for converting 1-D array to tensor, every 100 rows are taken and from that the mean of the values are calculated and made to store in a separate column. This process is done for entire dataset. In our case, we did this on the "Close" column as it's the main column where we would decide the prediction of the stock data.

After this step, we would obtain tensors for CNN side of model to train. Then, we split 80\% for training and 20\% for testing. Finally, we reshaped the data and sent it to the training phase. 

\subsection{Training Phase}\label{B}
After the dataset is processed, the NN model has to be made. In our case, it's the CNN-LSTM Neural Network model. 

For our model, we considered to divide the model into two parts, CNN and LSTM.

\subsubsection{CNN}
For the CNN section of model, we followed a custom way instead of ascending kind of way in the size of layers. So, we made 3 layers of neuron size 64,128,64 with MaxPooling layers in between. Finally we added a Flatten layer at end of CNN section to convert the tensors back to 1-D array.

All CNN layers are added with TimeDistributed function in order to train every temporal slice of input, as we're approaching a Time-Series problem in this case. Then, the processed data is sent to LSTM layers.

\subsubsection{LSTM}
For the LSTM section, we made 2 Bi-LSTM layers to detect the features and train them forward \& backward. For each layer, the neuron size is 200. Additionally, dropout layers are added in between with value of 0.25 and 0.5 in drop some features for stability.

Last, we added a dense layer with linear activation function and at the final layer we used "adam" optimizer ("sgd" also worked in this case but we found "adam" optimizer to be accurate after analysis), Mean Squared Error (mse) as the loss function and "mse" as the metric which is explained at first.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{model_arch-1.png}}
\caption{The proposed model architecture}
\label{model}
\end{figure}

The architecture for the model is shown in Fig. \ref{model}. After the model is trained, we made it to plot the graph for the loss values (both training and validation) and at first it proved to be less and later varied accordingly (shown in Fig. \ref{loss-1} and \ref{loss-2}.). But the loss and mse varies when the model is saved and made to train again with saved parameters (this is fully explained in the testing phase). Then, we managed to refine the test dataset back to arrays using the reshape() function, then made the model to predict the dataset. The graph is plotted and the results proved to be great. The model was able to predict the stock data with given time series and it's shown in Fig. \ref{predict-1}. 

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.7]{loss-1.png}}
\caption{The loss graph obtained during training}
\label{loss-1}
\end{figure}

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.7]{loss-2.png}}
\caption{MAE obtained during training}
\label{loss-2}
\end{figure}

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.7]{predict_1.png}}
\caption{The prediction graph for sample NSE/NASDAQ data}
\label{predict-1}
\end{figure}

\subsection{Testing Phase}
After the model has been trained and the values are noted, we saved the model in HDF5 format using Keras API in TensorFlow library. Then, we loaded the HDF5 file and tried training the model again but this time with the different dataset, we were able to train the model but the loss value varies accordingly. For example, if the loss is 0.055 during training phase, the loss increases to 0.153 (estimated, not accurate). It is also found that this happens depending on the dataset we use, for NIFTY sample dataset the error didn't occur whereas in the NASDAQ dataset it occured while loading up the saved model.

We tested and experimented the model with different datasets from Kaggle consisting sample data of mixed content from different stock markets \cite{b10}, NIFTY-50 \cite{b11}, NASDAQ and NYSE \cite{b12} to find how the model copes up with different stock market (shown in Fig. \ref{predict-1} and Fig. \ref{predict-2}). 

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.7]{predict_2.png}}
\caption{The prediction graph for sample NIFTY data}
\label{predict-2}
\end{figure}

\subsection{Deployment}
This section is considered as minimal one because we used Kaggle notebooks in order to create and deploy the models but we realised some developers who don't work with Kaggle and prefer local environments and tools like Conda. So, we made a Docker Image for them in order to work with Jupyterlab (instead of Jupyter notebook) with the GitHub repository as the folder. Initially, it was hard because by default, Docker Images are huge in size because of the OS images like Ubuntu. We got the image size as 250MB at first (without installing any Python libraries) and 750MB when uncompressed. We also tried to use pre-defined images for Jupyter notebooks where the libraries are already installed and ready, but we didn't use them as they are of huge size (approximately 3GB). So we added some libraries and made a docker image with Conda environment (via miniconda) on top of it, still we reached 1GB of data due to the size of libraries and scripts bundled so it's considered to be used only when a user doesn't want to use Kaggle as a working environment.

For deploying the image to Docker Hub, we used GitHub actions which is a CI tool from GitHub to write a CI action in which an image is published every time a change or release is made, so that users need not build image everytime locally. Docker Inc. already made a GitHub action \cite{b13} to perform the above functions, so we used and modified it to build and push Docker images. Similarly, we also made Helm charts if a person needs to run the Docker Image in a Kubernetes cluster. Initially we faced difficulties but after trial and error, we were able to expose the service to the network and run our Docker Image in Kubernetes. The Helm charts are deployed on the Artifact Hub (https://artifacthub.io) and anyone can download the templates from the repository.

\section{End Product}
After several works and tests, we were able to obtain a great working CNN-LSTM Neural Network model which can able to predict most of the stocks when the relevant stock market data is provided. In order to check how our model performed, we compared with other models which are obtained during the literature survey and found the results in table \ref{compare}

\begin{table}
\label{compare}
\begin{tabular}{c1c1}
\hline
\multicolumn{4}{c}{Comparison and analysis} \\
\hline
\multicolumn{2}{c}{Model} & \multicolumn{2}{c}{Accuracy} \\
\hline
\multicolumn{2}{c}{CNN-LSTM} & \multicolumn{2}{c}{MSE = 0.003 (Avg), 0.001 (Max)} \\
\multicolumn{2}{c}{Random Forest \cite{b1}} & \multicolumn{2}{c}{EVS = -0.400594} \\
\multicolumn{2}{c}{AELSTM \cite{b2}} & \multicolumn{2}{c}{53\% (Avg)} \\
\multicolumn{2}{c}{LBL-LSTM (Proposed) \cite{b3}} & \multicolumn{2}{c}{0.017 (Train), 0.026 (Test)} \\
\multicolumn{2}{c}{LSTM (Decentralized) \cite{b9}} & \multicolumn{2}{c}{MSE = 0.0003} \\
\hline
\end{tabular}
\end{table}

The model experimented from \cite{b3} is proposed one and haven't been tested rigorously. The model from \cite{b9} performed well and stated that an average of 0.0003 to 0.0004. In our case, we obtained an MSE of 0.001 maximum but varied accordingly with different datasets we experimented.

\section {Conclusion}
Designing a customised CNN-LSTM is bit tricky at first, because there are many algorithms already present to predict the stock data, however not fully optimized. We trained and tested the model with different kinds of datasets like NYSE, NASDAQ and NIFTY and found that accuracy of the model varies accordingly. For NIFTY \cite {b11}, the model proved to be good and predicted at most 99\% of stocks even during the testing stage. But for other datasets like NYSE \cite{b12}, the accuracy varied during the testing phase and not during training. We believe it may be due to the noise present in the dataset during the testing phase and compiling it again. Also, we obtained MSE of value 0.001 to 0.005 (approx) during training and 0.002 to 0.005 (approx) for validation with different datasets. For MAE, the values ranged from 0.2 to 0.5 for training and 0.3 to 0.5 for testing. Overall, the paper presents on how CNN can be combined with LSTM to obtain the features from the tensors processed from dataset and detect patterns based on the features obtained. The paper also presents one of the ways in which stock market can be predicted with great accuracy.


\begin{thebibliography}{00}
\bibitem{b1} Kompella, S., \& Chakravarthy Chilukuri, K. C. C. (2020). Stock Market Prediction Using Machine Learning Methods. International Journal of Computer Engineering and Technology, 10(3), 2019.
\bibitem{b2} Pang, X., Zhou, Y., Wang, P., Lin, W., \& Chang, V. (2020). An innovative neural network approach for stock market prediction. The Journal of Supercomputing, 76(3), 2098-2118.
\bibitem{b3} Gurav, U., \& Kotrappa, D. S. (2020). Impact of COVID-19 on stock market performance using efficient and predictive LBL-LSTM based mathematical model. International Journal on Emerging Technologies11 (4), 108-115.
\bibitem{b4} Kimoto, T., Asakawa, K., Yoda, M., \& Takeoka, M. (1990, June). Stock market prediction system with modular neural networks. In 1990 IJCNN international joint conference on neural networks (pp. 1-6). IEEE.
\bibitem{b5} Guresen, E., Kayakutlu, G., \& Daim, T. U. (2011). Using artificial neural network models in stock market index prediction. Expert Systems with Applications, 38(8), 10389-10397.
\bibitem{b6} Nelson, D. M., Pereira, A. C., \& de Oliveira, R. A. (2017, May). Stock market's price movement prediction with LSTM neural networks. In 2017 International joint conference on neural networks (IJCNN) (pp. 1419-1426). IEEE.
\bibitem{b7} Selvin, S., Vinayakumar, R., Gopalakrishnan, E. A., Menon, V. K., \& Soman, K. P. (2017, September). Stock price prediction using LSTM, RNN and CNN-sliding window model. In 2017 international conference on advances in computing, communications and informatics (icacci) (pp. 1643-1647). IEEE.
\bibitem{b8} Hiransha, M., Gopalakrishnan, E. A., Menon, V. K., \& Soman, K. P. (2018). NSE stock market prediction using deep-learning models. Procedia computer science, 132, 1351-1362.
\bibitem{b9} Bansal, G., Hasija, V., Chamola, V., Kumar, N., \& Guizani, M. (2019, December). Smart stock exchange market: a secure predictive decentralized model. In 2019 IEEE Global Communications Conference (GLOBECOM) (pp. 1-6). IEEE.
\bibitem{b10} Kaggle, Huge Stock Market Dataset (online). Link: https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs
\bibitem{b11} Kaggle, NIFTY-50 Stock Market Data (2000-2021) (online). Link: https://www.kaggle.com/rohanrao/nifty50-stock-market-data
\bibitem{b12} Kaggle, Stock Market Data (NASDAQ, NYSE, S\&P500). Link: https://www.kaggle.com/paultimothymooney/stock-market-data
\bibitem{b13} GitHub, Build and Push Docker images (GitHub Action), Link: https://github.com/marketplace/actions/build-and-push-docker-images

\end{thebibliography}
\vspace{12pt}

\end{document}
